{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"LFTBspJVcGoZ"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)\n","\n","model_folder = \"/content/gdrive/MyDrive/fine-tuned-pegasus-ariv\"\n","\n","# Create the folder if it does not exist\n","!mkdir -p \"{model_folder}\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W07vX966D5VF"},"outputs":[],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pZtDfXKLD3Sz"},"outputs":[],"source":["!pip install transformers[sentencepiece] datasets sacrebleu rouge_score py7zr -q"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CId8y2MWD3S0"},"outputs":[],"source":["# import libraries\n","\n","from transformers import pipeline, set_seed, AutoModelForSeq2SeqLM, AutoTokenizer\n","# from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n","import pandas as pd\n","from datasets import load_dataset, load_metric\n","import nltk\n","from nltk.tokenize import sent_tokenize\n","import matplotlib.pyplot as plt\n","import torch\n","from tqdm import tqdm\n","from datasets import load_dataset\n","nltk.download(\"punkt\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DbUxGzePFJU-"},"outputs":[],"source":["# load model and tokenizer\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","pretrained_model = \"google/pegasus-cnn_dailymail\"\n","tokenizer = AutoTokenizer.from_pretrained(pretrained_model)\n","pegasus_pretrained = AutoModelForSeq2SeqLM.from_pretrained(pretrained_model).to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BHcFqeppE64Y"},"outputs":[],"source":["technical_articles_dataset = load_dataset('scientific_papers', 'arxiv')\n"]},{"cell_type":"code","source":["print(type(technical_articles_dataset))\n","print(technical_articles_dataset)"],"metadata":{"id":"cwW2OeYUHSdn"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ke5jLcjMIVcG"},"outputs":[],"source":["# Reduce dataset size\n","# Calculate the new dataset sizes while maintaining the initial ratio\n","try_train_size = 7000\n","train_size = try_train_size\n","total_initial_size = technical_articles_dataset['train'].num_rows + technical_articles_dataset['validation'].num_rows + technical_articles_dataset['test'].num_rows\n","new_validation_size = int(technical_articles_dataset['validation'].num_rows * train_size / technical_articles_dataset['train'].num_rows)\n","new_test_size = int(technical_articles_dataset['test'].num_rows * train_size / technical_articles_dataset['train'].num_rows)\n","\n","# Shuffle the datasets\n","shuffled_train = technical_articles_dataset['train'].shuffle(seed=420)\n","shuffled_validation = technical_articles_dataset['validation'].shuffle(seed=420)\n","shuffled_test = technical_articles_dataset['test'].shuffle(seed=420)\n","\n","# Select the new dataset sizes\n","reduced_train = shuffled_train.select(range(train_size))\n","reduced_validation = shuffled_validation.select(range(new_validation_size))\n","reduced_test = shuffled_test.select(range(new_test_size))\n","\n","# Update dataset with the reduced version\n","technical_articles_dataset['train'] = reduced_train\n","technical_articles_dataset['validation'] = reduced_validation\n","technical_articles_dataset['test'] = reduced_test\n","\n","print(type(technical_articles_dataset))\n","print(technical_articles_dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0rT1xWhTD3S1"},"outputs":[],"source":["def chunk_creation(dataset, batch_size):\n","    for i in range(0, len(dataset), batch_size):\n","        yield dataset[i : i + batch_size]\n","\n","def compute_rouge_scores(data, rouge_reference, model, tokenizer, batch_size=16, device=device, column_text=\"article\", column_summary=\"abstract\"):\n","\n","    # divide the data set into chunks of size = \"batch_size\"\n","    batches_of_articles = list(chunk_creation(data[column_text], batch_size))\n","    batches_of_targets = list(chunk_creation(data[column_summary], batch_size))\n","\n","    # for each chunk, pass it into the model, generate the corresponding summaries and store them for rougue score calculation\n","    for article_batch, target_batch in tqdm(zip(batches_of_articles, batches_of_targets), total=len(batches_of_articles)):\n","\n","        model_input = tokenizer(article_batch, max_length=1024,  truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n","        model_output = model.generate(input_ids=model_input[\"input_ids\"].to(device), attention_mask=model_input[\"attention_mask\"].to(device), length_penalty=0.8, num_beams=8, max_length=128)\n","        summaries = [tokenizer.decode(s, skip_special_tokens=True, clean_up_tokenization_spaces=True) for s in model_output]      \n","        summaries = [d.replace(\"<n>\", \" \") for d in summaries]\n","        rouge_reference.add_batch(predictions=summaries, references=target_batch)\n","        \n","    #  calculate rougue scores\n","    rouge_scores = rouge_reference.compute()\n","    return rouge_scores"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2zCasQkCHa2t"},"outputs":[],"source":["# Rouge average for 5 docs\n","rouge_names = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]\n","\n","rouge_metric = load_metric('rouge')\n","score1 = compute_rouge_scores(technical_articles_dataset['test'][:5], rouge_metric, pegasus_pretrained, tokenizer, column_text = 'article', column_summary='abstract', batch_size=8 )\n","rouge_dict = dict((rn, score1[rn].mid.fmeasure ) for rn in rouge_names )\n","\n","pd.DataFrame(rouge_dict, index = ['pegasus'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d3BtLSwIsDBS"},"outputs":[],"source":["def generate_features(data_input):\n","    encodings_input = tokenizer(data_input['article'] , max_length = 1024, truncation = True)\n","    with tokenizer.as_target_tokenizer():\n","        encodings_target = tokenizer(data_input['abstract'], max_length = 128, truncation = True)\n","\n","        \n","    return {\n","        'input_ids' : encodings_input['input_ids'],\n","        'attention_mask': encodings_input['attention_mask'],\n","        'labels': encodings_target['input_ids']\n","    }\n"," \n","technical_articles_dataset_pt = technical_articles_dataset.map(generate_features, batched = True)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NPBlTswlsDBS"},"outputs":[],"source":["from transformers import DataCollatorForSeq2Seq\n","seq2seq_data_collator = DataCollatorForSeq2Seq(tokenizer, model=pegasus_pretrained)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8QhU8OgXsDBS"},"outputs":[],"source":["from transformers import TrainingArguments, Trainer\n","\n","model_folder = \"/content/gdrive/MyDrive/fine-tuned-pegasus-ariv\"\n","\n","trainer_args = TrainingArguments( output_dir=model_folder, num_train_epochs=1, warmup_steps=500,\n","                                  per_device_train_batch_size=1, per_device_eval_batch_size=1,\n","                                  weight_decay=0.01, logging_steps=10,\n","                                  evaluation_strategy='steps', eval_steps=500, save_steps=1e6,\n","                                  gradient_accumulation_steps=16\n","              ) \n","\n","\n","trainer = Trainer(model=pegasus_pretrained, args=trainer_args,\n","                  tokenizer=tokenizer, data_collator=seq2seq_data_collator,\n","                  train_dataset=technical_articles_dataset_pt[\"train\"], \n","                  eval_dataset=technical_articles_dataset_pt[\"validation\"])\n","\n","trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9NjDHlV5pDYX"},"outputs":[],"source":["# save the fine-tuned model\n","\n","model_folder = \"/content/gdrive/MyDrive/fine-tuned-pegasus-ariv\"\n","trainer.model.save_pretrained(model_folder)\n","tokenizer.save_pretrained(model_folder)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tv6cojGGsDBS"},"outputs":[],"source":["# Evaluate the performance of fine-tuned model\n","\n","rougue_scores = compute_rouge_scores(technical_articles_dataset['test'], rouge_metric, trainer.model, tokenizer, batch_size = 2, column_text = 'article', column_summary= 'abstract')\n","rouge_dict = dict((rn, rougue_scores[rn].mid.fmeasure ) for rn in rouge_names )\n","pd.DataFrame(rouge_dict, index = [f'pegasus'] )\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lV-yIdBYsDBT"},"outputs":[],"source":["# save: 7, \n","num = 4\n","sample_text = technical_articles_dataset[\"test\"][num][\"article\"]\n","reference = technical_articles_dataset[\"test\"][num][\"abstract\"]\n","\n","# Load the fine-tuned model and tokenizer\n","from transformers import PegasusForConditionalGeneration, PegasusTokenizer, PegasusConfig, TrainingArguments, Trainer, pipeline\n","model_folder = \"/content/gdrive/MyDrive/fine-tuned-pegasus-ariv\"\n","model = PegasusForConditionalGeneration.from_pretrained(model_folder)\n","tokenizer = PegasusTokenizer.from_pretrained(model_folder)\n","\n","\n","pipe = pipeline(\"summarization\", model=model, tokenizer=tokenizer)\n","pipe_out = pipe(technical_articles_dataset['test'][num]['article'][:1024] )\n","\n","## \n","import textwrap\n","print(\"Article:\")\n","print(sample_text)\n","\n","print(\"\\nReference Summary:\")\n","print(reference)\n","\n","print(\"\\nModel Summary:\")\n","summary = pipe_out[0][\"summary_text\"]\n","wrapped_summary = textwrap.fill(summary, width=80)\n","print(wrapped_summary)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"27uIThNuzh_V"},"outputs":[],"source":["summary = pipe_out[0][\"summary_text\"]\n","\n","import textwrap\n","wrapped_summary = textwrap.fill(summary, width=80)\n","\n","print(\"Summary:\")\n","print(wrapped_summary)\n"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1sR3q9inMl6ozYJTjUFDPOr7zhP9TuUMX","timestamp":1682535471958}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.9.14 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.14"},"vscode":{"interpreter":{"hash":"36cf16204b8548560b1c020c4e8fb5b57f0e4c58016f52f2d4be01e192833930"}}},"nbformat":4,"nbformat_minor":0}